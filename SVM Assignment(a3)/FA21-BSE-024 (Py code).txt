# Date: 17th April 2024
# Fahad Ajmal
# FA21-BSE-024


QUESTION:1


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC

data = pd.read_csv("dataset-q-1.csv")


X = data.iloc[:, :-1]
y = data.iloc[:, -1]

svm_model = SVC(kernel='linear')
svm_model.fit(X, y)


def plot_decision_boundary(X, y, model):
    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1
    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                         np.arange(y_min, y_max, 0.1))

    Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.contourf(xx, yy, Z, levels=[Z.min(), 0, Z.max()], alpha=0.4, cmap=plt.cm.bwr)

    plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=plt.cm.bwr, marker='o', edgecolor='k', label='Data Points')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('Decision Boundary and Data Points')
    plt.legend()
    plt.show()

plot_decision_boundary(X, y, svm_model)


QUESTION:2

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC

data = pd.read_csv("dataset-q-1.csv")

# Separate features (X) and labels (y)
X = data.iloc[:, :-1]
y = data.iloc[:, -1]

C_values = [0.01, 100, 300, 700, 1000]

for C in C_values:
    # Fit a linear SVM model with the current value of C
    svm_model = SVC(kernel='linear', C=C)
    svm_model.fit(X, y)

    def plot_decision_boundary(X, y, model):
        x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1
        y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))

        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)

        plt.contourf(xx, yy, Z, alpha=0.4)

        plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, marker='o', edgecolor='k', label='Data Points')
        plt.xlabel('Feature 1')
        plt.ylabel('Feature 2')
        plt.title(f'Decision Boundary with C={C}')
        plt.legend()
        plt.show()

    plot_decision_boundary(X, y, svm_model)

QUESTION:3 

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import numpy as np
import matplotlib.pyplot as plt

iris = datasets.load_iris()
X = iris.data[:, :2]  # Use the first two features
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def fit_svm_and_evaluate(kernel, C=None, degree=None, sigma=None):
    if kernel == 'poly':
        model = SVC(kernel='poly', C=C, degree=degree)
    elif kernel == 'rbf':
        model = SVC(kernel='rbf', C=C, gamma=(1 / (2 * (sigma ** 2))))

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    plt.figure()
    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, marker='o', edgecolor='k', label='Training Data')
    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, marker='^', edgecolor='k', label='Testing Data')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(f'Decision Boundary with {kernel} kernel (Accuracy: {accuracy:.2f})')
    
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))

    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.bwr)

    plt.legend()
    plt.show()
    
    return accuracy

kernel_settings = [
    {'kernel': 'poly', 'C': 1.0, 'degree': 2},
    {'kernel': 'rbf', 'C': 1.0, 'sigma': 1.0}
]

for settings in kernel_settings:
    kernel = settings['kernel']
    C = settings.get('C')
    degree = settings.get('degree')
    sigma = settings.get('sigma')

    accuracy = fit_svm_and_evaluate(kernel, C, degree, sigma)
    print(f"Kernel: {kernel}, C: {C}, Degree: {degree}, Sigma: {sigma}, Accuracy: {accuracy}")

polynomial_settings = [
    {'C': 1.0, 'degree': 2},
    {'C': 0.5, 'degree': 2},
    {'C': 1.0, 'degree': 3}
]

for setting in polynomial_settings:
    C = setting['C']
    degree = setting['degree']

    accuracy = fit_svm_and_evaluate('poly', C=C, degree=degree)
    print(f"Accuracy for polynomial kernel with C={C} and degree={degree}: {accuracy}")

gaussian_settings = [
    {'C': 1.0, 'sigma': 1.0},
    {'C': 0.5, 'sigma': 1.0},
    {'C': 1.0, 'sigma': 2.0}
]

for setting in gaussian_settings:
    C = setting['C']
    sigma = setting['sigma']

    accuracy = fit_svm_and_evaluate('rbf', C=C, sigma=sigma)
    print(f"Accuracy for Gaussian kernel with C={C} and sigma={sigma}: {accuracy}")



QUESTION: 4

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


data = pd.read_csv("dataset-q-4.csv")


X = data.iloc[:, :-1]
y = data.iloc[:, -1]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]}


svm_model = SVC(kernel='rbf')


grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)


optimal_C = grid_search.best_params_['C']
optimal_gamma = grid_search.best_params_['gamma']

optimal_svm_model = SVC(kernel='rbf', C=optimal_C, gamma=optimal_gamma)
optimal_svm_model.fit(X_train, y_train)

y_pred = optimal_svm_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

print("Optimal values:")
print(f"C: {optimal_C}")
print(f"Gamma: {optimal_gamma}")
print(f"Accuracy: {accuracy}")
